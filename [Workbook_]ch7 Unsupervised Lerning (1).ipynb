{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JTxsWF-5sXG"
   },
   "source": [
    "\n",
    "# [KDT] ch7 Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering / PCA / Association Rule \n",
    "\n",
    " - 데이터셋: 직장인 연봉 정보 / 보스톤 집값 / 식료품 정보 데이터셋 \n",
    " - 주요 라이브러리: sklearn linear_model / sklearn.decomposition / mlxtend.preprocessing \n",
    " - 알파 퀴즈(1개) / 파이 퀴즈(1개) / 시그마 퀴즈(2개) / 오메가 퀴즈(과제 1개) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\OneDrive\\\\문서\\\\Office\\\\DS 2022\\\\DS강의(onedrive)\\\\강의\\\\KDT\\\\2차_230227\\\\실습'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1668725561526,
     "user": {
      "displayName": "jinyang park",
      "userId": "06576046992691541404"
     },
     "user_tz": -540
    },
    "id": "Dtoe4P7Hwi_G"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1668725562530,
     "user": {
      "displayName": "jinyang park",
      "userId": "06576046992691541404"
     },
     "user_tz": -540
    },
    "id": "2P_tOya1wwd_"
   },
   "outputs": [],
   "source": [
    "# 원본 파일 로딩 \n",
    "df_hk = pd.read_csv('.\\\\data\\\\hk_221206.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\alpha$(알파) 퀴즈:\n",
    "\n",
    "직장인 연봉 정보 데이터셋을 바탕으로 군집분석을 진행하고자 한다.\n",
    "<br> 군집분석 진행 전 워밍업으로 지표간 거리 구하기 문제를 풀어 보고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>p(x1, y1), q(x2, y2) 일때 上) 맨허튼 거리, 下) 유클리드 거리 수식은 아래와 같다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$d\\left( p,q\\right)   = |x_{1}-x_{2}| + |y_{1}-y_{2}| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$d\\left( p,q\\right)   = \\sqrt {  \\left( x_{1}-x_{2}\\right)^2 + \\left( y_{1}-y_{2}\\right)^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>jumin7</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>company</th>\n",
       "      <th>grades</th>\n",
       "      <th>salary</th>\n",
       "      <th>expenditure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hkd1</td>\n",
       "      <td>990623-2</td>\n",
       "      <td>F</td>\n",
       "      <td>161.9</td>\n",
       "      <td>22</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>4100</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hkd10</td>\n",
       "      <td>900303-2</td>\n",
       "      <td>F</td>\n",
       "      <td>169.4</td>\n",
       "      <td>31</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>4720</td>\n",
       "      <td>2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hkd100</td>\n",
       "      <td>681205-2</td>\n",
       "      <td>F</td>\n",
       "      <td>168.3</td>\n",
       "      <td>55</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>7280</td>\n",
       "      <td>5905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hkd101</td>\n",
       "      <td>931226-2</td>\n",
       "      <td>F</td>\n",
       "      <td>155.3</td>\n",
       "      <td>28</td>\n",
       "      <td>AB</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>4060</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hkd102</td>\n",
       "      <td>920123-1</td>\n",
       "      <td>M</td>\n",
       "      <td>188.6</td>\n",
       "      <td>29</td>\n",
       "      <td>O</td>\n",
       "      <td>B</td>\n",
       "      <td>F</td>\n",
       "      <td>4390</td>\n",
       "      <td>4015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name    jumin7 gender  height  age blood_type company grades  salary  \\\n",
       "0    hkd1  990623-2      F   161.9   22          A       A      A    4100   \n",
       "1   hkd10  900303-2      F   169.4   31          A       A      B    4720   \n",
       "2  hkd100  681205-2      F   168.3   55          A       A      B    7280   \n",
       "3  hkd101  931226-2      F   155.3   28         AB       B      B    4060   \n",
       "4  hkd102  920123-1      M   188.6   29          O       B      F    4390   \n",
       "\n",
       "   expenditure  \n",
       "0         1975  \n",
       "1         2970  \n",
       "2         5905  \n",
       "3         2935  \n",
       "4         4015  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hk[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary         4100\n",
       "expenditure    1975\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#첫번째 데이터인 hkd1 의 정보값\n",
    "df_hk.iloc[0, 8:10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary         4720\n",
       "expenditure    2970\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#두번째 데이터인 hkd10 의 정보값\n",
    "df_hk.iloc[1, 8:10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>quiz1)</b> 데이터셋의 첫번째 샘플과 두번째 샘플의 맨허튼거리를 구하라(변수는 salary, expenditure 2가지 활용) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(df_hk.iloc[0,9] - df_hk.iloc[1,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(4100-4720) + abs(1975-2970)\n",
    "abs(df_hk.iloc[0,8] - df_hk.iloc[1,8]) + abs(df_hk.iloc[0,9] - df_hk.iloc[1,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>quiz2)</b> 데이터셋의 첫번째 샘플과 두번째 샘플의 유클리드 거리를 구하라(변수는 salary, expenditure 2가지 활용) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1172.358733494147"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df_hk.iloc[0,8] - df_hk.iloc[1,8])**2 + (df_hk.iloc[0,9] - df_hk.iloc[1,9])**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-0 Clustering 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17:35분 까지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_hk 데이터 셋 250개 샘플을 활용하여 군집을 만들어 세그먼트 분석을 하고자 한다. \n",
    "<br> 먼저 계층형 군집분석을 진행한다.  \n",
    "<br> 군집분석시 활용할 변수는 <b>gender, age, company, grades, salary, expenditure</b> 이다.   \n",
    "<br> 이때 수치형 변수 age, salary, expenditure는 정규화를 진행하고 정규화한 칼럼은 각각 age_st, salary_st, expenditure_st로 명명한다\n",
    "<br> 명목형 변수 gender, company, grades는 더미변수화 한다.(drop_first 옵션 false, 순서는 표기된 대로 진행할 것) \n",
    "<br> 전체 데이터셋 순서는 표준화한 age, salary, expenditure와 나머지 gender, company, grades 더미변수다.  \n",
    "\n",
    "<br>\n",
    "<br> 위 전처리를 마친 후 데이터셋 이름은 <b>basetable1</b>로 명명한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>company</th>\n",
       "      <th>grades</th>\n",
       "      <th>salary</th>\n",
       "      <th>expenditure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>4100</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>31</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>4720</td>\n",
       "      <td>2970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  age company grades  salary  expenditure\n",
       "0      F   22       A      A    4100         1975\n",
       "1      F   31       A      B    4720         2970"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df 생성 gender, age, company, grades, salary, expenditure\n",
    "df_hk_1= df_hk[['gender', \"age\", \"company\", \"grades\", \"salary\", \"expenditure\" ]]\n",
    "df_hk_1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_st</th>\n",
       "      <th>salary_st</th>\n",
       "      <th>expenditure_st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.996162</td>\n",
       "      <td>-1.222845</td>\n",
       "      <td>-1.613278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.954082</td>\n",
       "      <td>-0.887000</td>\n",
       "      <td>-1.077579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.824798</td>\n",
       "      <td>0.499716</td>\n",
       "      <td>0.502599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.301442</td>\n",
       "      <td>-1.244513</td>\n",
       "      <td>-1.096422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.185655</td>\n",
       "      <td>-1.065756</td>\n",
       "      <td>-0.514960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age_st  salary_st  expenditure_st\n",
       "0 -1.996162  -1.222845       -1.613278\n",
       "1 -0.954082  -0.887000       -1.077579\n",
       "2  1.824798   0.499716        0.502599\n",
       "3 -1.301442  -1.244513       -1.096422\n",
       "4 -1.185655  -1.065756       -0.514960"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StandardScaling ['age', 'salary', 'expenditure']\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "st = StandardScaler().fit( df_hk_1[['age', 'salary', 'expenditure']])\n",
    "st_table = pd.DataFrame(st.transform(df_hk_1[['age', 'salary', 'expenditure']]), columns=['age_st', 'salary_st', 'expenditure_st'])\n",
    "st_table[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies ['gender', 'company', 'grades']\n",
    "df_dummy = pd.get_dummies( df_hk_1[['gender', 'company', 'grades']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>company</th>\n",
       "      <th>grades</th>\n",
       "      <th>salary</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>age_st</th>\n",
       "      <th>salary_st</th>\n",
       "      <th>expenditure_st</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>company_A</th>\n",
       "      <th>company_B</th>\n",
       "      <th>company_C</th>\n",
       "      <th>grades_A</th>\n",
       "      <th>grades_B</th>\n",
       "      <th>grades_C</th>\n",
       "      <th>grades_D</th>\n",
       "      <th>grades_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>4100</td>\n",
       "      <td>1975</td>\n",
       "      <td>-1.996162</td>\n",
       "      <td>-1.222845</td>\n",
       "      <td>-1.613278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>31</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>4720</td>\n",
       "      <td>2970</td>\n",
       "      <td>-0.954082</td>\n",
       "      <td>-0.887000</td>\n",
       "      <td>-1.077579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>55</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>7280</td>\n",
       "      <td>5905</td>\n",
       "      <td>1.824798</td>\n",
       "      <td>0.499716</td>\n",
       "      <td>0.502599</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>4060</td>\n",
       "      <td>2935</td>\n",
       "      <td>-1.301442</td>\n",
       "      <td>-1.244513</td>\n",
       "      <td>-1.096422</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>B</td>\n",
       "      <td>F</td>\n",
       "      <td>4390</td>\n",
       "      <td>4015</td>\n",
       "      <td>-1.185655</td>\n",
       "      <td>-1.065756</td>\n",
       "      <td>-0.514960</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  age company grades  salary  expenditure    age_st  salary_st  \\\n",
       "0      F   22       A      A    4100         1975 -1.996162  -1.222845   \n",
       "1      F   31       A      B    4720         2970 -0.954082  -0.887000   \n",
       "2      F   55       A      B    7280         5905  1.824798   0.499716   \n",
       "3      F   28       B      B    4060         2935 -1.301442  -1.244513   \n",
       "4      M   29       B      F    4390         4015 -1.185655  -1.065756   \n",
       "\n",
       "   expenditure_st  gender_F  gender_M  company_A  company_B  company_C  \\\n",
       "0       -1.613278         1         0          1          0          0   \n",
       "1       -1.077579         1         0          1          0          0   \n",
       "2        0.502599         1         0          1          0          0   \n",
       "3       -1.096422         1         0          0          1          0   \n",
       "4       -0.514960         0         1          0          1          0   \n",
       "\n",
       "   grades_A  grades_B  grades_C  grades_D  grades_F  \n",
       "0         1         0         0         0         0  \n",
       "1         0         1         0         0         0  \n",
       "2         0         1         0         0         0  \n",
       "3         0         1         0         0         0  \n",
       "4         0         0         0         0         1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basetable1\n",
    "basetable1 = pd.concat( [df_hk_1, st_table, df_dummy], axis=1)\n",
    "basetable1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>age_st</th>\n",
       "      <th>salary_st</th>\n",
       "      <th>expenditure_st</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>company_A</th>\n",
       "      <th>company_B</th>\n",
       "      <th>company_C</th>\n",
       "      <th>grades_A</th>\n",
       "      <th>grades_B</th>\n",
       "      <th>grades_C</th>\n",
       "      <th>grades_D</th>\n",
       "      <th>grades_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>250.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.240</td>\n",
       "      <td>6357.480</td>\n",
       "      <td>4971.480</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.654</td>\n",
       "      <td>1849.791</td>\n",
       "      <td>1861.113</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.002</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000</td>\n",
       "      <td>3080.000</td>\n",
       "      <td>1330.000</td>\n",
       "      <td>-2.228</td>\n",
       "      <td>-1.775</td>\n",
       "      <td>-1.961</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000</td>\n",
       "      <td>5002.500</td>\n",
       "      <td>3593.750</td>\n",
       "      <td>-0.723</td>\n",
       "      <td>-0.734</td>\n",
       "      <td>-0.742</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000</td>\n",
       "      <td>6100.000</td>\n",
       "      <td>4762.500</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000</td>\n",
       "      <td>7427.500</td>\n",
       "      <td>6272.500</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>55.000</td>\n",
       "      <td>11990.000</td>\n",
       "      <td>10865.000</td>\n",
       "      <td>1.825</td>\n",
       "      <td>3.051</td>\n",
       "      <td>3.173</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age     salary  expenditure   age_st  salary_st  expenditure_st  \\\n",
       "count  250.000    250.000      250.000  250.000    250.000         250.000   \n",
       "mean    39.240   6357.480     4971.480   -0.000      0.000           0.000   \n",
       "std      8.654   1849.791     1861.113    1.002      1.002           1.002   \n",
       "min     20.000   3080.000     1330.000   -2.228     -1.775          -1.961   \n",
       "25%     33.000   5002.500     3593.750   -0.723     -0.734          -0.742   \n",
       "50%     39.000   6100.000     4762.500   -0.028     -0.139          -0.113   \n",
       "75%     46.000   7427.500     6272.500    0.783      0.580           0.700   \n",
       "max     55.000  11990.000    10865.000    1.825      3.051           3.173   \n",
       "\n",
       "       gender_F  gender_M  company_A  company_B  company_C  grades_A  \\\n",
       "count   250.000   250.000    250.000    250.000    250.000   250.000   \n",
       "mean      0.448     0.552      0.400      0.400      0.200     0.316   \n",
       "std       0.498     0.498      0.491      0.491      0.401     0.466   \n",
       "min       0.000     0.000      0.000      0.000      0.000     0.000   \n",
       "25%       0.000     0.000      0.000      0.000      0.000     0.000   \n",
       "50%       0.000     1.000      0.000      0.000      0.000     0.000   \n",
       "75%       1.000     1.000      1.000      1.000      0.000     1.000   \n",
       "max       1.000     1.000      1.000      1.000      1.000     1.000   \n",
       "\n",
       "       grades_B  grades_C  grades_D  grades_F  \n",
       "count   250.000   250.000   250.000   250.000  \n",
       "mean      0.464     0.128     0.064     0.028  \n",
       "std       0.500     0.335     0.245     0.165  \n",
       "min       0.000     0.000     0.000     0.000  \n",
       "25%       0.000     0.000     0.000     0.000  \n",
       "50%       0.000     0.000     0.000     0.000  \n",
       "75%       1.000     0.000     0.000     0.000  \n",
       "max       1.000     1.000     1.000     1.000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable1.describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Clustering - Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age_st, salary_st, expenditure_st, gender, company, grades 각각 더미변수 총 13개 변수를 바탕으로 Hierarchical 군집분석을 시행한다\n",
    "<br>(sklearn AgglomerativeClustering 진행) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_st</th>\n",
       "      <th>salary_st</th>\n",
       "      <th>expenditure_st</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>company_A</th>\n",
       "      <th>company_B</th>\n",
       "      <th>company_C</th>\n",
       "      <th>grades_A</th>\n",
       "      <th>grades_B</th>\n",
       "      <th>grades_C</th>\n",
       "      <th>grades_D</th>\n",
       "      <th>grades_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.996162</td>\n",
       "      <td>-1.222845</td>\n",
       "      <td>-1.613278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.954082</td>\n",
       "      <td>-0.887000</td>\n",
       "      <td>-1.077579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.824798</td>\n",
       "      <td>0.499716</td>\n",
       "      <td>0.502599</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.301442</td>\n",
       "      <td>-1.244513</td>\n",
       "      <td>-1.096422</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.185655</td>\n",
       "      <td>-1.065756</td>\n",
       "      <td>-0.514960</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age_st  salary_st  expenditure_st  gender_F  gender_M  company_A  \\\n",
       "0 -1.996162  -1.222845       -1.613278         1         0          1   \n",
       "1 -0.954082  -0.887000       -1.077579         1         0          1   \n",
       "2  1.824798   0.499716        0.502599         1         0          1   \n",
       "3 -1.301442  -1.244513       -1.096422         1         0          0   \n",
       "4 -1.185655  -1.065756       -0.514960         0         1          0   \n",
       "\n",
       "   company_B  company_C  grades_A  grades_B  grades_C  grades_D  grades_F  \n",
       "0          0          0         1         0         0         0         0  \n",
       "1          0          0         0         1         0         0         0  \n",
       "2          0          0         0         1         0         0         0  \n",
       "3          1          0         0         1         0         0         0  \n",
       "4          1          0         0         0         0         0         1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대상 df 생성, age_st, salary_st, expenditure_st, gender, company, grades 각각 더미변수 총 13개 변수\n",
    "basetable_cluster_1 = basetable1.iloc[ : , 6:]\n",
    "basetable_cluster_1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgglomerativeClustering\n",
    "\n",
    "cluster_1 = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward').fit(basetable_cluster_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'euclidean'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attribute\n",
    "cluster_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2,\n",
       "       2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2,\n",
       "       1, 2, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 2, 0, 0, 2,\n",
       "       0, 0, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 0, 1, 0, 0, 1, 2, 0, 0,\n",
       "       0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cluster_1.labels_\n",
    "cluster_1.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 계층형 군집분석 시각화: dendrogram(60개 샘플 대상)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dendrogram 그리기 (10개)\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dendrogram 그리기 (60개)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측, 새로운 정보값으로 예측할때 사용\n",
    "# basetable1['cluster_hier'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 타겟값 맵핑 {0:'a', 1:'b', 2:'c'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster / company에 따른 scatter plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 회사별 분류 \n",
    "\n",
    "fig, ax = plt.subplots( nrows= 1 , ncols=2, figsize=(14, 5))\n",
    "sns.scatterplot(x='age', y='salary', data=basetable1, hue='company',  palette='Set1', ax= ax[0] )\n",
    "sns.scatterplot(x='age', y='salary', data=basetable1, hue='cluster_hier',  palette='Set2', ax=ax[1] )\n",
    "\n",
    "ax[0].set_title('category : company ')\n",
    "ax[1].set_title('category : hierarchy cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hierarchy cluster는 군집 A: 고 연령 / 고 연봉 , 군집 B: 중상 연령, 중저 연봉, 군집 C: 저 연령 / 저 연봉 으로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable1.groupby(['cluster_hier'])[['age', 'salary', 'expenditure']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable1.groupby(['cluster_hier'])[['age', 'salary', 'expenditure']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. Clustering - K means\n",
    "\n",
    "age_st, salary_st, expenditure_st, gender, company, grades 각각 더미변수 총 13개 변수를 바탕으로 K-means 군집분석을 시행한다\n",
    "<br> (sklearn KMeans 진행, n_cluster = 3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basetable_cluster_1 (df, age_st, salary_st, expenditure_st, gender, company, grades 각각 더미변수 총 13개 변수)\n",
    "basetable_cluster_1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><kmeans split 에러시 threadpoolctl 업그레이드 필요> </b>\n",
    "<br>!pip install threadpoolctl --user --upgrade\n",
    "<br>import threadpoolctl\n",
    "<br>threadpoolctl.__version__ <- 3.0 이상 필요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means 모델 n_clusters=3, random_state=123\n",
    "# cluster_1_2 = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Attribute 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k - means 라벨값 \n",
    "# basetable1['cluster_kmean'] = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# crosstab 'cluster_hier' 'cluster_kmean'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# crosstab 'company' 'cluster_kmean'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회사별 분류 \n",
    "\n",
    "fig, ax = plt.subplots( nrows= 1 , ncols=3, figsize=(16, 5))\n",
    "sns.scatterplot(x='age', y='salary', data=basetable1, hue='company',        palette='Set1', ax=ax[0] )\n",
    "sns.scatterplot(x='age', y='salary', data=basetable1, hue='cluster_hier',   palette='Set1', ax=ax[1] )\n",
    "sns.scatterplot(x='age', y='salary', data=basetable1, hue='cluster_kmean',  palette='Set1', ax=ax[2] )\n",
    "\n",
    "ax[0].set_title('category : company ')\n",
    "ax[1].set_title('category : hierarchy cluster')\n",
    "ax[2].set_title('category : kmeans cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4. Clustering 평가 - Elbow score\n",
    "- kmeans inertia_ 활용\n",
    "\n",
    "Inertia 값, 군집화후 각 중심점에서 군집의 데이타간 거리를 합산한것으로 응집도를 나타내는 값 \n",
    "\n",
    "값이 작을 수록 응집도가 높게 군집화가 잘되었다고 평가할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# n_clusters=k를 1부터 10까지 적용\n",
    "\n",
    "inertias = []\n",
    "mapping = {}\n",
    "K = range(1, 10)\n",
    "\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(basetable_cluster_1) \n",
    "    inertias.append(kmeanModel.inertia_)\n",
    "    mapping[k] = kmeanModel.inertia_\n",
    "    print('k값 ', k , '=>', kmeanModel.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow score 시각화\n",
    "plt.plot(np.arange(1, 10), inertias, 'bx-')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('The Elbow Method using Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-5. Clustering 평가 - Silhouette Test\n",
    "\n",
    "silhouette score는 1에 가까워야 positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_score = pd.DataFrame(columns =['k', 'score'])\n",
    "for i in np.arange(2, 7):\n",
    "    model_clustering = KMeans( n_clusters=i, random_state=123).fit(basetable_cluster_1)\n",
    "    a = silhouette_score( basetable_cluster_1,model_clustering.labels_)\n",
    "    k = pd.DataFrame({'k':[i], 'score':[a]})\n",
    "    k_score = pd.concat([k_score, k]).reset_index(drop=True)\n",
    "    print(\"K값 \", i, \" silhouette score: \", a.round(3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x='k', y='score', data=k_score)\n",
    "plt.xticks([2, 3, 4, 5, 6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K 값에 따른 scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K값 2~5까지 cluster_model, cluster_label 생성\n",
    "cluster_model_k1 = KMeans( n_clusters=2, random_state=123).fit(basetable_cluster_1)\n",
    "cluster_model_k2 = KMeans( n_clusters=3, random_state=123).fit(basetable_cluster_1)\n",
    "cluster_model_k3 = KMeans( n_clusters=4, random_state=123).fit(basetable_cluster_1)\n",
    "cluster_model_k4 = KMeans( n_clusters=5, random_state=123).fit(basetable_cluster_1)\n",
    "\n",
    "cluster_plot = basetable1.copy()\n",
    "cluster_plot['cluster_k1'] = cluster_model_k1.labels_\n",
    "cluster_plot['cluster_k2'] = cluster_model_k2.labels_\n",
    "cluster_plot['cluster_k3'] = cluster_model_k3.labels_\n",
    "cluster_plot['cluster_k4'] = cluster_model_k4.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K별 Plot \n",
    "\n",
    "fig, ax = plt.subplots( nrows= 2 , ncols=2, figsize=(8, 8))\n",
    "sns.scatterplot(x='age', y='salary', data=cluster_plot, hue='cluster_k1',  palette='Set1', ax= ax[0][0] )\n",
    "sns.scatterplot(x='age', y='salary', data=cluster_plot, hue='cluster_k2',  palette='Set1', ax=ax[0][1] )\n",
    "sns.scatterplot(x='age', y='salary', data=cluster_plot, hue='cluster_k3',  palette='Set1', ax=ax[1][0] )\n",
    "sns.scatterplot(x='age', y='salary', data=cluster_plot, hue='cluster_k4',  palette='Set1', ax=ax[1][1] )\n",
    "\n",
    "\n",
    "ax[0][0].set_title('K : 2')\n",
    "ax[0][1].set_title('K : 3')\n",
    "ax[1][0].set_title('K : 4')\n",
    "ax[1][1].set_title('K : 5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-6. Clustering 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "250개 데이터 셋을 바탕으로 군집분석을 실시 하였다.\n",
    "<br> 250개 외 추가 데이터 셋 샘플을 추가 할 경우, 모델을 바탕으로 기존 군집분석을 바탕으로 Cluster를 분류 할 수 있다. \n",
    "<br> 모델은 Kmeans 알고리즘을 통해 3개 cluster로 분류한 cluster_1_2 모델을 활용한다.\n",
    "\n",
    "<br> 데이터셋 샘플 - 성별:남성 / age:33 / company :C / grades: B / salary : 4500 / expenditure: 2975\n",
    "\n",
    "<br> <b>작업순서</b>\n",
    "<br> 1.수치형 변수 표준화 -> 2. 더미변수 확인 -> 3. 데이터 프레임에 맞춰 데이터 셋 준비 -> 4.Cluster 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basetable1\n",
    "basetable1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basetable_cluster_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_1 나이:33, 연봉:4500, 소비액:2975\n",
    "#sample_1 = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기존 표준화 모델 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_1 DataFrame 변경\n",
    "#sample_1_num = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy DataFrame 생성\n",
    "#sample_1_dummy =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy변수 정보값 생성, 'gender_M', 'company_C', 'grades_B'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 최종 DataFrame 만들기, sample_1_num,  sample_1_dummy concat\n",
    "# predic_sample1 = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predic_sample1로 cluster 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz) 추가 예측 \n",
    "\n",
    "<br> cluster 예측모델로 아래 데이터의 결과를 예측하시오 \n",
    "<br> 성별:여성 / age:43 / company :B / grades: B / salary : 7900 / expenditure: 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 DataFrame을 사용하여 sample DataFrame 만들기 : to_dict() 활용\n",
    "\n",
    "\n",
    "#z표준화\n",
    "\n",
    "# 추가 정보값 입력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존방법\n",
    "sample_2 = pd.DataFrame({'age':[43], 'salary':[7900], 'expenditure':[6000]})\n",
    "sample_2_num = pd.DataFrame( st.transform(sample_2), columns = ['age_st', 'salary_st', 'expenditure_st'])\n",
    "sample_2_dummy = pd.DataFrame( [[0, 0,0,0,0,0,0,0,0,0]], columns = df_dummy.columns)\n",
    "sample_2_dummy['gender_F'][0] = 1\n",
    "sample_2_dummy['company_B'][0] = 1\n",
    "sample_2_dummy['grades_B'][0] = 1\n",
    "predic_sample2 = pd.concat([ sample_2_num, sample_2_dummy], axis=1)\n",
    "\n",
    "predic_sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predic_sample2로 cluster 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. $\\pi$(파이) 퀴즈 : 붓꽃 데이터 셋 활용 Kmeans / Hierachy \n",
    "\n",
    "sklearn 라이브러리 활용을 통한 붓꽃 품종 분류 \n",
    "<br>\n",
    "<br> 워밍업: x축을 'sepal_length'으로 y축을 'petal_length'로 scatter plot을 도식화 하시오. \n",
    "<br> 이때 라이브러리는 seaborn을 활용하고 'species' 그룹에 따라 색깔을 다르게 표현하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩 \n",
    "df_iris = pd.read_csv('.\\\\data\\\\iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris scatter plot, x='sepal_length',  y='petal_length'\n",
    "\n",
    "fig  = plt.figure( figsize=(5, 5))\n",
    "sns.scatterplot( data =df_iris, x='sepal_length',  y='petal_length', hue='species')\n",
    "\n",
    "plt.title('iris scatter plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> 계층형 군집분석을 통해 3개의 군집으로 분류하고자 한다. \n",
    "<br> 수치형 4개 변수 모두 활용해 minmax 정규화를 1차로 수행한 후 \n",
    "<br> sklearn의 AgglomerativeClustering 메소드를 활용, 하이퍼 파라미터값은 하단을 참조하여 군집분석을 수행하라\n",
    "<br> (n_clusters=3, affinity='manhattan', linkage='average')\n",
    "<br>\n",
    "<br><b> 문제: 3개 클러스터별 'sepal_length' 평균을 확인하고 평균값이 가장 높은 클러스터의 'sepal_length' 평균을 구하라</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgglomerativeClustering, (n_clusters=3, affinity='manhattan', linkage='average')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.crosstab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "fig, ax = plt.subplots( nrows= 2 , ncols=2,  figsize=(10,10))\n",
    "\n",
    "sns.scatterplot( data = df_iris, x='sepal_length',  y='petal_length', hue='species' , palette='Set1', ax= ax[0][0])\n",
    "sns.scatterplot( data = df_iris,  x='sepal_length',  y='petal_length', hue='cluster', palette='Set2',ax= ax[0][1])\n",
    "sns.boxplot( data = df_iris, x='species', y='sepal_width' , palette='Set1', ax= ax[1][0])\n",
    "sns.boxplot( data = df_iris, x='cluster', y='sepal_width' , palette='Set2', ax= ax[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (추가) 집단간 sepal_length 평균 차이가 통계적으로 유의미하게 차이 나는지 확인해 보기 \n",
    "\n",
    "<br> species가 versicolor 인 데이터셋과 이와 유사한 클러스터와 sepal_length 평균 차이 확인해 본다.\n",
    "<br> shapiro 메소드를 통해 정규성을 확인하고 scipy의 ttest_ind 메소드를 활용할 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro, ttest_ind\n",
    "\n",
    "# p-vaue 0.05 이상이면 정규성 만족 \n",
    "\n",
    "\n",
    "# shapiro Test, p-vaue 0.05 이상이면 정규성 만족 \n",
    "\n",
    "\n",
    "# 두 집단의 평균의 차이, ttest_ind\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PCA \n",
    "\n",
    "<br> 주성분 분석(Principal Component Analysis, PCA) 가장 널리 사용되는 차원 축소 기법 중 하나\n",
    "<br> iris 데이터 활용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot('sepal_length', 'sepal_width', data=df_iris_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#공분산행렬 확인 \n",
    "import numpy as np \n",
    "cov_matrix = np.cov(df_iris_std.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##고유값(분산설명력, explained_variance), 고유벡터 추출(사영계수, components)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#고유값(분산설명력, explained_variance)\n",
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#고유벡터 추출(사영계수, components)\n",
    "eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_iris = pd.DataFrame({'pca1':df_iris_std @ eigenvectors.T[0], 'pca2':df_iris_std @ eigenvectors.T[1], \n",
    "                         'pca3':df_iris_std @ eigenvectors.T[2], 'pca4':df_iris_std @ eigenvectors.T[3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 비교 \n",
    "fig, ax = plt.subplots( nrows= 1 , ncols=2,  figsize=(6,3))\n",
    "\n",
    "sns.scatterplot('sepal_length', 'sepal_width', data=df_iris_2,   ax= ax[0])\n",
    "sns.scatterplot('pca1', 'pca2',                data=pca_iris,    ax= ax[1])\n",
    "\n",
    "ax[0].set_title('sepal_length, sepal_width')\n",
    "ax[1].set_title('pca1, pca2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA 라이브러리 \n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#고유값(분산설명력, explained_variance), eigenvalues 비교\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#고유벡터 확인(사영계수, components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pca1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenvectors로 계산한것과 비교\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform으로 PCA 계산, df_iris_std @ pc.components_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 누적 분산 설명력(explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누적 분산 설명력(explained_variance_ratio_) 시각화\n",
    "sns.lineplot(x = [1,2,3,4], y=pc.explained_variance_ratio_.cumsum())\n",
    "plt.xticks([1,2,3,4])\n",
    "plt.title('explained_variance_ratio_')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 콘크리트 데이터 셋 활용, PCA 통해 만든 합성변수로 종속변수 strength을 예측하는 다중 회귀 분석 모델 설계\n",
    "<br>1030 rows × 9 columns\n",
    "<br> 라이브러리 : from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brick_concrete.csv 파일 로딩\n",
    "df_brick = pd.read_csv('.\\\\data\\\\yellowbrick_concrete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brick.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 변수별 상관계수 매트릭스 플롯 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "fig = plt.figure( figsize=(5,5))\n",
    "\n",
    "sns.heatmap( df_brick.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#다중 공선성 VIF 로 feature 특성 파악\n",
    "# case1\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['features'] = df_brick.columns\n",
    "vif['VIF'] = [variance_inflation_factor(df_brick.values, i) for i in range(df_brick.shape[1])]\n",
    "vif.sort_values('VIF', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF 지수가 10 초과하는 변수들이 다수 존재 \n",
    "<br> PCA를 통해 차원 축소, 복잡성을 줄이자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA 프로세스\n",
    "<br>1.정규화 -> 2. 공분산 행렬 계산 -> 3. 공분산 행렬 고유벡터와 고유값 계산 -> 4. 주성분 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 공분산 행렬 계산 / 3. 공분산 행렬 고유벡터와 고유값 계산\n",
    "sklearn.decomposition 라이브러리를 통해 자동 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#고유값  \n",
    "# pd.Series( pca_model.explained_variance_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#고유벡터 (사영계수)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 주성분 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합성변수의 수는 행 수: 데이터셋 수 / 칼럼 수 : 데이터셋 칼럼 수\n",
    "데이터셋 칼럼 수 만큼의 합성 변수가 만들어 진다.\n",
    "<br>(ex: 10개의 칼럼이 있으면 PCA 후 합성변수 수는 총 10개) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#합성변수 transform + pca1~8 columns 생성 (1030 rows X 8 columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA 설명력 확인 6개 합성 변수를 통해 90% 이상 설명 가능 하다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 절차 정리\n",
    "1) df\n",
    "\n",
    "2) sc = StandardScaler().fit_transform(df)\n",
    "\n",
    "3) PCA().fit(sc) => explained_variance_ , explained_variance_ratio_\n",
    "\n",
    "4) PCA().fit_transform(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1) df (  df_brick_sc_1  )\n",
    "# 2) sc = StandardScaler().fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) PCA().fit(sc) => explained_variance_ , explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 4) PCA().fit_transform(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. $\\pi$(파이) 퀴즈 : 아래 회귀분석을 시행하고 평가결과를 비교하시오\n",
    "\n",
    " - case 1) 종속변수: df_brick['strength'], 독립변수: df_brick_sc 변수 8개 로 회귀분석\n",
    " - case 2) 종속변수: df_brick['strength'], 독립변수: df_brick_sc PCA합성변수 6개 로 회귀분석\n",
    " - case 1)과 case 2)의 RMSE를 비교하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brick_sc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brick_pca[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Asociation rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "250명의 식료품 구매 이력을 바탕으로 연관성 분석 수행\n",
    "<br> (file: hkdataset_associaterules.csv - 식료품 데이터셋)\n",
    "<br> (file: hk_221206.csv - hk_table, 회사원 데이터 셋)\n",
    "\n",
    "<br> A회사 임직원을 대상으로 연관성 규칙 확인 \n",
    "<br> 우유를 단일 선행으로 하는 규칙을 만들며 후행 품목 수는 상관없다.    \n",
    "<br> 이를 위해 A회사 100명의 식료품 구매 이력을 확인하여 A회사 임직원 대상으로 장바구니 분석을 수행한다.\n",
    "<br> 이때 우유를 선행으로 하는 규칙 중 Lift 값이 가장 높은 item은 무엇인지 확인하시오.\n",
    "<br> HINT: 식료품 데이터셋과 회사원 데이터셋을 join하여 사용. \n",
    "<br> \n",
    "<br><b> 관련 라이브러리 및 하이퍼 파라미터 값 </b>\n",
    "<br> from mlxtend.preprocessing import TransactionEncoder\n",
    "<br> from mlxtend.frequent_patterns import apriori, association_rules\n",
    "<br> 조건 min_support=0.1, min_confidence=0.01\n",
    "\n",
    "Asociation rules 를 위해 mlxtend install 필요\n",
    "\n",
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩\n",
    "df_asso = pd.read_csv('.\\\\data\\\\hkdataset_associaterules.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asso #250명의 식료품 구매 내역 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩 \n",
    "df_hk= pd.read_csv('.\\\\data\\\\hk_221206.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge (left join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A회사 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# case 1)\n",
    "# id별로 item 정리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import TransactionEncoder, apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransactionEncoder attribute 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransactionEncoder attribute 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apriori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# association_rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우유를 사는 고객은 후행으로 어떤 상품을 많이 사는지 lift 내림차순으로 정렬 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : Corn(lift: 1.59) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# case 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apriori\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# association_rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$(오메가) Quiz1 (연관규칙을 생성하고 아래에 답하시오)\n",
    "\n",
    "Mart (association_rules_mart.csv) 데이터셋 활용 \n",
    "<br>40,000 rows X 3 columns\n",
    "\n",
    "<br>1. 한 번에 2개를 구매한 것은 삭제하시오. (ID와 Item이 중복되는것)\n",
    "<br>hint: drop_duplicates (34,766 rows)\n",
    "<br>2. 연관성 규칙을 생성하시오 (min_support=0.005, min_threshold=0.005)\n",
    "<br>3. 선행(antecedents)이 단일 Item 인것을 대상으로 데이터 셋을 구성하시오\n",
    "<br>4. support가 0.01보다 큰 것중(>= 0.01) lift가 가장 높은 선행, 후행 Item을 고르시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# case1) pivot 사용\n",
    "# 파일 로딩\n",
    "df_mart = pd.read_csv('.\\\\data\\\\association_rules_mart.csv')\n",
    "df_mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) drop_duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2) min_support=0.005, min_threshold=0.005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# apriori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3) antecedents이 단일 Item 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mart_asso_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step4) support가 0.01 보다 큰 것중 lift가 가장 높은 선행과 후행을 고르시오\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 2) transactionencoder 사용\n",
    "# 파일 로딩\n",
    "df_mart_2 = pd.read_csv('.\\\\data\\\\association_rules_mart.csv')\n",
    "df_mart_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) drop_duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step2) min_support=0.005, min_threshold=0.005\n",
    "# step2) transactionencoding\n",
    "\n",
    "from mlxtend.preprocessing import transactionencoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apriori,  association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3) antecedents이 단일 Item 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step4) support가 0.01 보다 큰 것중 lift가 가장 높은 선행과 후행을 고르시오\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$(오메가) Quiz2 (연관규칙을 생성하고 아래에 답하시오)\n",
    "\n",
    "seaborn 라이브러리 택시 데이터셋 활용 \n",
    "<br>6433 rows × 14 columns\n",
    "\n",
    "<br> 당신은 미국 맨하탄에 공유자동차 서비스를 기획하고자 한다. \n",
    "<br> 프로토타입으로 Upper East Side North에서 출발하는 가장 가능성이 높은 공유 노선을 설정하고자 한다. \n",
    "<br> 이를 위해 아래 단계를 거쳐 연관성 분석을 수행한다. \n",
    "<br> 1. 결측치 제거 후 진행 \n",
    "<br> 2. 택시 데이터 셋을 바탕으로 색상은 노랑색(yellow)에 맨허튼에서 픽업을 한 택시로 필터링한 데이터를 바탕으로 분석을 진행한다. \n",
    "<br> 3. pickup_zone/ dropoff_zone 칼럼을 이용하여 파생변수('rules')를 생성한다. ([pickup_zone, dropoff_zone] 형식)\n",
    "<br> ex) pickup_zone = 'A', dropoff_zone = 'B' 일때 [A, B]로 생성\n",
    "     hint) \n",
    "<br> 4. from mlxtend.preprocessing import TransactionEncoder를 바탕으로 연관성 분석 전처리 데이터셋을 만들고\n",
    "<br> 5. 연관성 분석을 실행하시오 (최소 기준 support =0.001, confidence = 0.1)\n",
    "<br>  5-1. lift가 가장 높은 선행, 후행 구간을 구하시오\n",
    "<br>  5-2. Bloomingdale가 선행일때 lift 값이 가장 높은 후행을 찾으시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case1) TransactionEncoder 활용\n",
    "# step1 파일로딩, 결측치 제거,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2 yellow & Manhattan 필터링\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3  pickup_zone, dropoff_zone 파생변수 ('rules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quiz3['rules'] = [ [quiz3['pickup_zone'][i]] + [quiz3['dropoff_zone'][i]] for i in range(quiz3.shape[0]) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quiz3[['pickup_zone','dropoff_zone']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4. TransactionEncoder로 연관성 분석 전처리 데이터셋 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# te3.columns_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step5) apriori, min_support=0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step 5-1) association_rules 도출, lift 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step 5-2) Bloomingdale가 선행일때 lift 값이 가장 높은 후행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case2) pivot_table 활용\n",
    "# step1 파일로딩, 결측치 제거,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2 yellow & Manhattan 필터링\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3  pickup_zone, dropoff_zone 파생변수 ('rules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quiz3_1['rules'] = [ [quiz3_1['pickup_zone'][i]] + [quiz3_1['dropoff_zone'][i]] for i in range(quiz3_1.shape[0]) ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# quiz3_1 = quiz3_1.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4. 연관성 분석 전처리 데이터셋 생성\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas.DataFrame.melt\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html?highlight=melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table 생성\n",
    "quiz3_1_1 = quiz3_1.reset_index()\n",
    "quiz3_1_1_melt = quiz3_1_1.melt(id_vars='index',     value_vars=['pickup_zone','dropoff_zone'],     var_name=None,    value_name='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step5 apriori, min_support=0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step 5-1) association_rules 도출, lift 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step 5-2) Bloomingdale가 선행일때 lift 값이 가장 높은 후행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  $\\Sigma$ (시그마) Quiz ( 다이아몬드를 군집화하고 평균 가격을 분석하시오)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/shivam2503/diamonds\n",
    "\n",
    "데이터(diamonds.csv) 사이즈 : 53940 X 10\n",
    "<br> \n",
    "<br> <b>carat:</b> weight of the diamond (0.2--5.01)\n",
    "<br> <b>cut:</b> quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "<br> <b>color:</b> diamond colour, from D (best) to J (worst)\n",
    "<br> <b>clarity:</b> a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "<br> <b>depth:</b> total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n",
    "<br> <b>table:</b> width of top of diamond relative to widest point (43--95) \n",
    "<br> <b>price:</b> price in US dollars ($326--$18,823)\n",
    "<br> <b>x:</b> length in mm (0--10.74)\n",
    "<br> <b>y:</b> width in mm (0--58.9)\n",
    "<br> <b>z:</b> depth in mm (0--31.8)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quiz 1) diamond 데이터셋에 PCA를 적용하여 feature수를 줄이시오\n",
    "\n",
    "<br> 가장 값이 많이 나가는 다이아몬드 군집모형을 만들고자 한다. \n",
    "\n",
    "<br> 먼저 다이아몬드 데이터셋 중 carat은 0.7이상 0.8이하 데이터샘플만을 바탕으로한다. \n",
    "<br> 해당 데이터 셋의 모든 수치형 데이터를 활용하여 PCA를 진행한다(종속변수로 활용할 price는 제외)\n",
    "<br> 이때 분산설명력이 높은 순으로 확인할 시 누적 분산 설명력 90% 이상 확인할때 합성변수는 모두 몇개가 필요한가? \n",
    "\n",
    "<br> 이와 함께 위에서 확인한 변수 수를 바탕으로 PCA 합성변수로만 이루어진 데이터 셋을 만들고 데이터셋 명칭을 \n",
    "<br> quiz_table1 로 명명한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩\n",
    "quiz1 = pd.read_csv('.\\\\data\\\\diamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# carat이 0.7이상~0.8이하 샘플만 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 변수 추출 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분산설명력 확인, 90% 이상\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quiz_table 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quiz 2) diamond 데이터셋 - 계층형 군집 분석 후 모델 적합 \n",
    "\n",
    "<br>quiz_table1과 함께 이전 데이터셋에서의 모든 명목형 변수는 더미변수 처리(drop_first=True)하여 열결합을 수행한다.\n",
    "<br>이후 계층형 군집분석을 아래 옵션값을 확인하여 진행한다.\n",
    "<br>(메소드: AgglomerativeClustering, 클러스터 수 = 4, affinity='euclidean', linkage='ward')\n",
    "<br>클러스터별 다이아몬드 값 평균을 확인하고 평균값이 가장 높은 클러스터의 다이아몬드 평균값을 구하시오 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dummy 변수 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price, pca table, dummy table 결합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgglomerativeClustering (n_clusters=4, affinity='euclidean', linkage='ward')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균가격이 가장 높은 cluster은 ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quiz 3) 클러스터별 평균 차이가 실제 유의미한 차이가 있는지 ANOVA 분석 및 pairwise_tukeyhsd 사후 분석 수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_oneway ANOVA 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 분석결과 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clarity: (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut: (Fair, Good, Very Good, Premium, Ideal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# color: diamond colour, from D (best) to J (worst)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMDMucM2pMTNZILG4KX61Uv",
   "collapsed_sections": [
    "4JTxsWF-5sXG",
    "hfMi2HeL4piH",
    "5YwW9JcI1BcB",
    "0DC3DnJKED-q",
    "7OEylfG6Ou24",
    "z4IpIXV-edh3",
    "vhWiJegbvSiL",
    "rttRLvNIl51S",
    "X7ZNaAeiw8e1",
    "LrwKIIBM3AuA",
    "JpMOZEbbpdH6",
    "Ht5WvWhG6tun",
    "joz0fttoOWYJ"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
